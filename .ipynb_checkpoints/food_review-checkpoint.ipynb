{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "X = []\n",
    "Y = []\n",
    "with open('food_review_dataset.csv', encoding='utf8', errors='ignore') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for row in csvReader:\n",
    "        row[0] = re.sub('[^0-9a-zA-Z]+', ' ', row[0])\n",
    "        X.append(row[0])\n",
    "        Y.append(int(float(row[1])))\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly splitting into train, validation and test set\n",
    "seed = random.randint(0,2**32 - 1)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(X)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(Y)\n",
    "X_train = X[:int(len(X) * 0.7)]\n",
    "X_validation = X[int(len(X) * 0.7):int(len(X) * 0.9)]\n",
    "X_test = X[int(len(X) * 0.9):]\n",
    "Y_train = Y[:int(len(Y) * 0.7)]\n",
    "Y_validation = Y[int(len(Y) * 0.7):int(len(Y) * 0.9)]\n",
    "Y_test = Y[int(len(Y) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading GloVe embeddings\n",
    "with open('glove.6B.50d.txt', encoding='utf8', errors='ignore') as f:\n",
    "    words = set()\n",
    "    word_to_index = {}\n",
    "    index_to_word = {}\n",
    "    word_to_vec_map = {}\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        curr_word = line[0]\n",
    "        curr_word = re.sub('[^0-9a-zA-Z]+', '', curr_word)\n",
    "        curr_word = curr_word.strip()\n",
    "        if curr_word != '' and curr_word not in words:\n",
    "            words.add(curr_word)\n",
    "            word_to_index[curr_word] = i\n",
    "            index_to_word[i] = curr_word\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Negative Review\", \"Positive Review\"]\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index)\n",
    "    emb_dim = word_to_vec_map[\"the\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))    \n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the input sentences\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((X.shape[0], max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().strip().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            cw = word_to_index.get(w)\n",
    "            if cw is not None:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "                if j >= max_len:\n",
    "                    break\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_length)\n",
    "X_validation_indices = sentences_to_indices(X_validation, word_to_index, max_length)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_indices = Input(max_length, dtype = 'int32')\n",
    "embeddings = embedding_layer(sentence_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building an LSTM model\n",
    "lstm_X = LSTM(units = 64, dropout=0.7, return_sequences = True)(embeddings)\n",
    "lstm_X = LSTM(units = 128, dropout=0.7, return_sequences = True)(lstm_X)\n",
    "lstm_X = LSTM(units = 64, dropout=0.7, return_sequences = True)(lstm_X)\n",
    "lstm_X = LSTM(units = 64, dropout=0.7, return_sequences = False)(lstm_X)\n",
    "lstm_X = Dense(units = 32)(lstm_X)\n",
    "lstm_X = Dense(units = 16)(lstm_X)\n",
    "lstm_X = Dense(units = 8)(lstm_X)\n",
    "lstm_X = Dense(units = 1)(lstm_X)\n",
    "lstm_X = Activation('sigmoid')(lstm_X)\n",
    "lstm_model = Model(inputs = sentence_indices, outputs = lstm_X)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "lstm_cp = ModelCheckpoint('lstm.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_history = lstm_model.fit(X_train_indices, Y_train, epochs = 200, batch_size = 200, validation_data=(X_validation_indices, Y_validation), callbacks=[lstm_es, lstm_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the learning curve\n",
    "pyplot.plot(lstm_history.history['loss'], label='lstm_train')\n",
    "pyplot.plot(lstm_history.history['val_loss'], label='lstm_validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_model = load_model('lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring the test accuracy\n",
    "loss, acc = best_lstm_model.evaluate(X_test_indices, Y_test)\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a CNN model\n",
    "cnn_X = Conv1D(filters=128, kernel_size=7, padding='causal', activation='relu')(embeddings)\n",
    "cnn_X = MaxPooling1D(pool_size=2)(cnn_X)\n",
    "cnn_X = Dropout(0.4)(cnn_X)\n",
    "cnn_X = Conv1D(filters=64, kernel_size=7, padding='causal', activation='relu')(cnn_X)\n",
    "cnn_X = MaxPooling1D(pool_size=2)(cnn_X)\n",
    "cnn_X = Dropout(0.4)(cnn_X)\n",
    "cnn_X = Conv1D(filters=32, kernel_size=7, padding='causal', activation='relu')(cnn_X)\n",
    "cnn_X = GlobalMaxPooling1D()(cnn_X)\n",
    "cnn_X = Dropout(0.4)(cnn_X)\n",
    "cnn_X = Dense(units = 32)(cnn_X)\n",
    "cnn_X = Dense(units = 16)(cnn_X)\n",
    "cnn_X = Dense(units = 8)(cnn_X)\n",
    "cnn_X = Dense(units = 1)(cnn_X)\n",
    "cnn_X = Activation('sigmoid')(cnn_X)\n",
    "cnn_model = Model(inputs = sentence_indices, outputs = cnn_X)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "cnn_cp = ModelCheckpoint('cnn.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_history = cnn_model.fit(X_train_indices, Y_train, epochs = 200, batch_size = 200, validation_data=(X_validation_indices, Y_validation), callbacks=[cnn_es, cnn_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the learning curve\n",
    "pyplot.plot(cnn_history.history['loss'], label='cnn_train')\n",
    "pyplot.plot(cnn_history.history['val_loss'], label='cnn_validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model = load_model('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring the test accuracy\n",
    "loss, acc = best_cnn_model.evaluate(X_test_indices, Y_test)\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a hybrid(CNN + LSTM) model\n",
    "cnn_X = Conv1D(filters=128, kernel_size=7, padding='causal', activation='relu')(embeddings)\n",
    "cnn_X = MaxPooling1D(pool_size=2)(cnn_X)\n",
    "cnn_X = Dropout(0.4)(cnn_X)\n",
    "hybrid_X = LSTM(units = 64, dropout=0.7, return_sequences = True)(hybrid_X)\n",
    "hybrid_X = LSTM(units = 64, dropout=0.7, return_sequences = False)(hybrid_X)\n",
    "hybrid_X = Dense(units = 32)(hybrid_X)\n",
    "hybrid_X = Dense(units = 16)(hybrid_X)\n",
    "hybrid_X = Dense(units = 8)(hybrid_X)\n",
    "hybrid_X = Dense(units = 1)(hybrid_X)\n",
    "hybrid_X = Activation('sigmoid')(hybrid_X)\n",
    "hybrid_model = Model(inputs = sentence_indices, outputs = hybrid_X)\n",
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "hybrid_cp = ModelCheckpoint('hybrid.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hybrid_history = hybrid_model.fit(X_train_indices, Y_train, epochs = 200, batch_size = 200, validation_data=(X_validation_indices, Y_validation), callbacks=[hybrid_es, hybrid_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the learning curve\n",
    "pyplot.plot(hybrid_history.history['loss'], label='hybrid_train')\n",
    "pyplot.plot(hybrid_history.history['val_loss'], label='hybrid_validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hybrid_model = load_model('hybrid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring the test accuracy\n",
    "loss, acc = best_hybrid_model.evaluate(X_test_indices, Y_test)\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "While CNN is much faster than LSTM and appears to find the minimum in fewer epochs, LSTM can get upto 94% test accuracy compared to CNNs 91%.\n",
    "\n",
    "I found it optimal to use a hybrid which is moderately fast and gets close to 93% test accuracy.\n",
    "\n",
    "Still, more research must be done in order to differetiate these two approaches as hardware was a crucial bottleneck while conducting this project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
